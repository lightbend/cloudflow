#!/usr/bin/env bash

set -e

################################################
# Cloudflow installer bootstrap install script #
################################################

##### Helper functions

# Prints an error with red text to the console
#
# $1 - Error message
print_error_message() {
  local errorMessage=$1
  echo "$(tput setaf 1)$errorMessage$(tput sgr0)"
}

CLOUDFLOW_INSTALLER_IMAGE=$1
if [ -z "$CLOUDFLOW_INSTALLER_IMAGE" ]; then
    CLOUDFLOW_INSTALLER_IMAGE=lightbend/cloudflow-installer
fi
echo "Cloudflow installer image to be used: $CLOUDFLOW_INSTALLER_IMAGE"
echo

##### 1) Download yaml for the installer and Cloudflow CR
# Embedded Yaml, inserted by the Makefile

CLOUDFLOW_INSTALLER_YAML=""

CLOUDFLOW_YAML=""

WEBHOOK_PATCH_JOB_IMAGE=""

CLOUDFLOW_INSTALLER_IMAGE_TAG=""

CLOUDFLOW_OPERATOR_IMAGE_NAME=""
CLOUDFLOW_OPERATOR_IMAGE_TAG=""
CLOUDFLOW_SPARK_OPERATOR_IMAGE_NAME=""
CLOUDFLOW_SPARK_OPERATOR_IMAGE_TAG=""
CLOUDFLOW_FLINK_OPERATOR_IMAGE_NAME=""
CLOUDFLOW_FLINK_OPERATOR_IMAGE_TAG=""
KAFKA_IMAGE_NAME=""
KAFKA_IMAGE_TAG=""
STRIMZI_OPERATOR_IMAGE_NAME=""
STRIMZI_OPERATOR_IMAGE_TAG=""

##### 0.1) Test Cluster connection, check kubectl version, check bash version.

# requires kubectl
if kubectl help > /dev/null 2>&1
then
  true # nothing to do
else 
  print_error_message "kubectl must be available in order to run the bootstrap install script."
  exit 1
fi

KUBECTL_VERSION_MAJOR=$(kubectl --client=true version -o yaml | awk -F '"' '/major/ {print $2}')
KUBECTL_VERSION_MINOR=$(kubectl --client=true version -o yaml | awk -F '"' '/minor/ {print $2}')

# bash 4 or better
if [ "${BASH_VERSINFO}" -lt 4 ] | [ "${BASH_VERSINFO[0]}" -lt 4 ]
then
  print_error_message "Bash version must be >= 4 in order to run the bootstrap install script."
  exit 1
fi

# check cluster connection
if kubectl get nodes > /dev/null 2>&1
then
  true # nothing to do
else
  print_error_message "Unable to acces the Kubernetes cluster using kubectl. Please check the cluster connection."
  exit 1
fi

##### 0.2) Ask for storage classes

# The following commands extracts all storage classes with their provisioner and if the storage class is the default one.
kubectlOutput=$(kubectl get sc -o jsonpath='{ range .items[*]}{.metadata.name}{"\t"}{.provisioner}{"\t"}{.metadata.annotations.storageclass\.kubernetes\.io/is-default-class}{"\n"}{end}')

# A map where `key` is storage class and `value` is provisioner
declare -A clusterStorageClassProvisioner=(); while read -r a b c; do clusterStorageClassProvisioner["$a"]="$b"; done <<< "$kubectlOutput"
if [ $? -ne 0 ]; then
    print_error_message "The bootstrap install script has failed to connect to the cluster; please check your connect and try again."
    exit 1
fi
# Extract the default storage class (if any)
defaultStorageClass=$(echo "$kubectlOutput" | awk '$3 == "true" {print $1}')
# Make sure the map contains some entries
if [ ${#clusterStorageClassProvisioner[@]} == 0 ]; then
    print_error_message "Could not retrieve a list of registered storage classes from the cluster."
    print_error_message "This may indicate that the cluster currently has no configured storage classes." 
    print_error_message "Cloudflow needs to create Persistent Volumes (PV) for components" 
    print_error_message "like Kafka and Spark to work. PVs require you to register one or more storage classes."
    print_error_message "For more information, please see the Cloudflow installation guide."
    exit 1
fi
# Create a list of keys from the map
clusterStorageClassKeys=(${!clusterStorageClassProvisioner[@]})

# List of verified RWM provisioners
declare -a readWriteManyProvisioners=(
    "kubernetes.io/glusterfs"
    "kubernetes.io/azure-file"
    "kubernetes.io/quobyte"
    "kubernetes.io/nfs"
)
# List of verified RWO provisioners
declare -a readWriteOnceProvisioners=(
    "kubernetes.io/aws-ebs"
    "kubernetes.io/azure-file"
    "kubernetes.io/azure-disk"
    "kubernetes.io/gce-pd"
    "kubernetes.io/glusterfs"
    "kubernetes.io/rbd"
    "kubernetes.io/quobyte"
    "kubernetes.io/nfs"
    "kubernetes.io/vsphere-volume"
    "kubernetes.io/scaleio"
    "kubernetes.io/storageos"
    "kubernetes.io/portworx-volume"
)

# The function takes one parameter, and that is the number of
# entries in the list that the user selects from.
#
# $1 - The number of entries to select from
#
# The function returns the index of the selected class.
queryStorageClass() {
    local lowerBound=1
    local upperBound=$1

    selectedClassIndex=""
    returnValue=""
    # Keep asking until we get something
    while [[ -z "$returnValue" ]]
    do
        read -p "> " selectedClassIndex
        if [ "$selectedClassIndex" -ge "$lowerBound" ] && [ "$selectedClassIndex" -le "$upperBound" ]; then
            returnValue=$selectedClassIndex
        else
            returnValue="-1"
        fi
    done
    echo $returnValue
}

# Prints detected storage classes and our classification of them for this type of access mode.
#
# $1 - The list of provisioners capable of creating volumes with the requested access mode.
#
# The function does not return anything.
printSelection() {
    classification=$1
    shift 1
    local provisionerList=("$@")
    count=1
    printf "   %-20s %-30s %-20s%s\n" "Name" "Provisioner" "$classification"       "Cluster default"
    printf "   %-20s %-30s %-20s%s\n" "----" "-----------" "${classification//?/-}" "---------------"
    for i in "${!clusterStorageClassProvisioner[@]}"
    do
        # Check if provisioner is in list
        local found=false
        for element in "${provisionerList[@]}"; do
            if [[ $element == ${clusterStorageClassProvisioner[$i]} ]]; then
                found=true
            fi
        done

        supportAccessMode="unknown"
        if [ "$found" == true ]
        then
            supportAccessMode="yes"
        fi

        clusterDefault="-"
        if [ "$i" == "$defaultStorageClass" ]
        then
            clusterDefault="yes"
        fi

        printf "%s. %-20s %-30s %-20s%s\n" $count $i ${clusterStorageClassProvisioner[$i]} "$supportAccessMode" "$clusterDefault"

        ((count++))
    done
}

echo ""
echo "Select a storage class for workloads requiring ReadWriteMany persistent volumes."
echo "Examples of these workloads are Spark and Flink checkpointing and savepointing."
echo ""
printSelection "ReadWriteMany" "${readWriteManyProvisioners[@]}"

selectedIndex=-1
while [[ "$selectedIndex" == -1 ]]
do
    selectedIndex=$(queryStorageClass ${#clusterStorageClassProvisioner[@]})
    if [[ $selectedIndex == -1 ]]; then 
        print_error_message "The value you selected is not a valid choice. Valid values are between 1 and ${#clusterStorageClassProvisioner[@]}."
    fi
done
export selectedRWMStorageClass=${clusterStorageClassKeys[(($selectedIndex-1))]}

echo ""
echo "Select a storage class for workloads requiring ReadWriteOnce persistent volumes."
echo "Examples of these workloads are Kafka, Zookeeper, and Prometheus."
echo ""
printSelection "ReadWriteOnce" "${readWriteOnceProvisioners[@]}"

selectedIndex=-1
while [[ "$selectedIndex" == -1 ]]
do
    selectedIndex=$(queryStorageClass ${#clusterStorageClassProvisioner[@]})
    if [[ $selectedIndex == -1 ]]; then 
        print_error_message "The value you selected is not a valid choice. Valid values are between 1 and ${#clusterStorageClassProvisioner[@]}."
    fi
done
export selectedRWOStorageClass=${clusterStorageClassKeys[(($selectedIndex-1))]}

echo ""
echo "- Using storage class '$selectedRWMStorageClass' for workloads requiring persistent volumes with 'ReadWriteMany' access mode."
echo "- Using storage class '$selectedRWOStorageClass' for workloads requiring persistent volumes with 'ReadWriteOnce' access mode."
echo ""

##### 4) Apply the installer yaml

echo
echo "Bootstrapping the Cloudflow installer..."
echo

if [ "$KUBECTL_VERSION_MAJOR" -ge 1 ] && [ "$KUBECTL_VERSION_MINOR" -ge 18 ]
then
  KUBECTL_OPTION="--dry-run=client"
else
  KUBECTL_OPTION="--dry-run"
fi

echo "$CLOUDFLOW_INSTALLER_YAML" | \
  sed -e "s~CLOUDFLOW_INSTALLER_IMAGE_TAG_PH~$CLOUDFLOW_INSTALLER_IMAGE_TAG~" \
      -e "s~CLOUDFLOW_INSTALLER_IMAGE_PH~$CLOUDFLOW_INSTALLER_IMAGE~" | \
  kubectl apply -f -

##### 5) Wait for installer deployment rollout

echo
echo -n "Waiting for Cloudflow installer availability..."

DEPLOYMENT_AVAILABILITY=0
while [ "$DEPLOYMENT_AVAILABILITY" != "1" ]
do
  echo -n '.'
  sleep 5
  DEPLOYMENT_AVAILABILITY=$(kubectl get -n cloudflow-installer deployments | awk '/cloudflow-installer-deployment/ {print $4}')
done

CRD_AVAILABILITY=0
while [ "$CRD_AVAILABILITY" != "1" ]
do
  echo -n '.'
  sleep 5
  CRD_AVAILABILITY=$(kubectl get crds | awk '/cloudflows.cloudflow-installer.lightbend.com/ {print "1"}')
done

echo
echo "Bootstrapping the Cloudflow installer - done."

##### 6) Apply the Cloudflow CR 

echo
echo "Installing Cloudflow..."
echo

# getting cloudflow-installer-deployment uid

CLOUDFLOW_CRD_UID=$(kubectl get -o jsonpath='{.metadata.uid}' crd cloudflows.cloudflow-installer.lightbend.com)

echo "$CLOUDFLOW_YAML" | \
  sed -e "s~RWO_STORAGE_CLASS_PH~$selectedRWOStorageClass~g" \
      -e "s~RWM_STORAGE_CLASS_PH~$selectedRWMStorageClass~g" \
      -e "s~WEBHOOK_PATCH_JOB_IMAGE_PH~$WEBHOOK_PATCH_JOB_IMAGE~" \
      -e "s~CLOUDFLOW_SPARK_OPERATOR_IMAGE_NAME_PH~$CLOUDFLOW_SPARK_OPERATOR_IMAGE_NAME~" \
      -e "s~CLOUDFLOW_SPARK_OPERATOR_IMAGE_TAG_PH~$CLOUDFLOW_SPARK_OPERATOR_IMAGE_TAG~" \
      -e "s~CLOUDFLOW_FLINK_OPERATOR_IMAGE_NAME_PH~$CLOUDFLOW_FLINK_OPERATOR_IMAGE_NAME~" \
      -e "s~CLOUDFLOW_FLINK_OPERATOR_IMAGE_TAG_PH~$CLOUDFLOW_FLINK_OPERATOR_IMAGE_TAG~" \
      -e "s~CLOUDFLOW_OPERATOR_IMAGE_NAME_PH~$CLOUDFLOW_OPERATOR_IMAGE_NAME~" \
      -e "s~CLOUDFLOW_OPERATOR_IMAGE_TAG_PH~$CLOUDFLOW_OPERATOR_IMAGE_TAG~" \
      -e "s~KAFKA_IMAGE_NAME_PH~$KAFKA_IMAGE_NAME~" \
      -e "s~KAFKA_IMAGE_TAG_PH~$KAFKA_IMAGE_TAG~" \
      -e "s~STRIMZI_OPERATOR_IMAGE_NAME_PH~$STRIMZI_OPERATOR_IMAGE_NAME~" \
      -e "s~STRIMZI_OPERATOR_IMAGE_TAG_PH~$STRIMZI_OPERATOR_IMAGE_TAG~" \
      -e "s~CLOUDFLOW_CRD_UID_PH~$CLOUDFLOW_CRD_UID~" | \
  kubectl apply -f -

echo
echo "Cloudflow installation triggered"
