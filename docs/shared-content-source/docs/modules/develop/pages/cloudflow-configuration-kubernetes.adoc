
:page-partial:

include::ROOT:partial$include.adoc[]

== Available Kubernetes Settings 

In this section we are covering the different Kubernetes parameters that are configurable. 

Several Kubernetes settings for a streamlet can be set under `cloudflow.streamlets.[streamlet-name].kubernetes`.
On the following samples we show configurations under a specific streamlet, `my-streamlet`, that in its complete path is `cloudflow.streamlets.my-streamlet`. It is also possible, as explained in xref:develop:cloudflow-configuration.adoc#_configuring_a_runtime_using_the_runtime_scope[Configuring a Runtime using the runtime Scope], to apply any configuration shown in here to any `runtimes`. The complete path for a runtime is, for instance, `cloudflow.runtimes.akka`.

=== Resources and Environment Variables

Container resource requirements and environment variables can be set in the `cloudflow.streamlets.[streamlet-name].kubernetes.pods.pod.containers.container` section.
The example below shows how resource requirements are set specifically for a `my-streamlet` streamlet:

[source, hocon]
----
cloudflow.streamlets.my-streamlet {
  kubernetes.pods.pod {
    containers.container {
      env = [ 
            { name = "JAVA_OPTS" 
              value = "-XX:MaxRAMPercentage=40.0"
            },{
              name = "FOO"
              value = "BAR"
            }
          ]
      resources {
        requests {
          cpu = "500m"
          memory = "512Mi"
        }
        limits {
          memory = "4Gi"
        }
      }
    }
  }
}
----

The above example shows that `500mcpu` is requested, as well as `512Mi` of memory. 
The pod is limited to use `4Gi` of memory. It also shows how to set the environment variable `JAVA_OPTS=XX:MaxRAMPercentage=40.0` and `FOO=BAR`  


===  Labels

To set pod labels, add the `labels` section shown in the example below:

[source, hocon]
----
cloudflow.streamlets.my-streamlet {
  kubernetes.pods.pod {
    labels {
      key1 = value1
      key2 = value2
    }
  }
}
----

The example above shows how to add the labels `key1 = value1` and `key2 = value2` to the pod for streamlet `my-streamlet`. 

===  Annotations

Similar to labels we can add annotations to any streamlet pod. The snippet below shows how:

[source, hocon]
----
cloudflow {
  streamlets {
    my-streamlet {
      kubernetes {
        pods.pod {
          annotations {
            key1 = annotation1
          }
        }
      }
    }
  }
}
----

This configuration adds the anotation `key: annotation1` to the container where `my-akka-streamlet` is deployed.

Annotations, same as labels, are defined by a key/value and also can be defined specifically for a streamlet or for all streamlets of a runtime, under `cloudflow.runtimes.akka.kubernetes.pods.pod.annotations`. 

===  Container Ports

To add container ports we need to at least provide a `container-port` number. The snippet below shows how:

[source, hocon]
----
cloudflow {
  streamlets {
    my-streamlet {
      kubernetes {
        pods.pod.containers.container {
          ports = [
            { container-port=9001},
            { container-port=9002, host-ip="10.132.0.123", protocol = "SCTP", host-port=9999, name="user-datagram"}
          ]
        }
      }
    }
  }
}
----

It is possible, as we showed above, to also set host-ip, protocol, host-port and a name. 
This configuration adds two container ports to every container where `my-akka-streamlet` is deployed. One in 9001 as TCP and the other in 9002 as UDP with `Host Ports:9999/UDP`, `name: user-datagram` and `hostIp: 10.132.0.123`

For more info on kubernetes API https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.20/#containerport-v1-core[container port]

Note:
Only Akka Streamlets can open ports 

=== Volumes and Volume-Mounts
==== **Mounting Secrets**

It possible to add `volumes`, that contain a secret, and mount them into the container with `volume-mounts`. Bear in mind that each `kubernetes.pods.pod.containers.container.volume-mounts` name must match a `kubernetes.pods.pod.volumes` name in the config. 

Here's a sample, and further explanation, of how to configure two secrets to be mounted on a container. 

[source, hocon]
----
cloudflow.streamlets.my-streamlet {
  kubernetes.pods.pod {
   volumes {
      foo {
        secret {
          name = mysecret1
        }
      }
      bar {
        secret {
          name = mysecret2
        }
      }
    }
    containers.container {
      volume-mounts {
        foo {
          mount-path = "/mnt/folderA"
          read-only = true
        }
        bar {
          mount-path = "/mnt/folderB"
          read-only = true
        }
      }
    }
  } 
}
----

This configuration will mount `mysecret1` into each `my-streamlet` container on to the path `/mnt/folderA/mysecret1` as read-only, while `mysecret2` will be mounted on path `/mnt/folderB/mysecret2`. Inside these folders, you'll find as many files as values are under the https://kubernetes.io/docs/concepts/configuration/secret/#decoding-a-secret[`data`] tag in the Kubernetes Secret mounted.
As each `volume-mounts` name must match a `volumes` name, `volume-mounts.foo` matches `volumes.foo` and `volume-mounts.bar` matches `volumes.bar`.

.Configuration available to mount secrets
[%autowidth]
|===
| resource  | key
| `volumes` | `kubernetes.pods.pod.volumes.[name].secret.name = [secret-name]`
| `volume-mounts` | `pod.containers.container.volume-mounts.[name].mount-path = [some-path]`
| `volume-mounts` | `pod.containers.container.volume-mounts.[name].read-only = [true or false]`
|===


==== **Mounting Persistent Volume Claims**

You can also mount `volumes` on Persistent Volume Claims (PVC) that already exist in the Kubernetes cluster. They are also mounted into the container with `volume-mounts`. If the PVC doesn't not exist in the cluster, an error is shown and the deployment or configuration is stopped.

Here's a sample, and further explanation, of how to configure two PVC's to be mounted on all the deployed containers of `my-streamlet`. 

[source, hocon]
----
cloudflow.streamlets.my-streamlet {
  kubernetes.pods.pod {
   volumes {
      foo {
        pvc {
          name = myclaim1
          read-only = true
        }
      }
      bar {
        pvc {
          name = myclaim2
          read-only = false
        }
      }
    }
    containers.container {
      volume-mounts {
        foo {
          mount-path = "/mnt/folderA"
          read-only = true
        }
        bar {
          mount-path = "/mnt/folderB"
          read-only = false
        }
      }
    }
  } 
}
----

This configuration will mount an existing Persistent Volume Claim `myclaim1` into each `my-streamlet` container on to the path `/mnt/folderA` as read-only, while `myclaim2` will be mounted on path `/mnt/folderB` as writable. As each `volume-mounts` name must match a `volumes` name, `volume-mounts.foo` matches `volumes.foo` and `volume-mounts.bar` matches `volumes.bar`.



.Configuration available to choose pvc and mount it
[%autowidth]
|===
| resource  | key
| `volumes` | `kubernetes.pods.pod.volumes.[name].pvc.name = [pvc-name]`
| `volumes` | `kubernetes.pods.pod.volumes.[name].pvc.read-only = [true or false]`
| `volume-mounts` | `pod.containers.container.volume-mounts.[name].mount-path = [some-path]`
| `volume-mounts` | `pod.containers.container.volume-mounts.[name].read-only = [true or false]`
|===


=== Pod differences among Akka, Flink and Spark Streamlets.

Akka runtimes only deploy one pod per streamlet while Flink and Sparks deploy two. Spark creates a Driver pod and a Executor pod, while Flink creates a JobManager and a TaskManager.

When we are setting Kubernetes configuration via `kubernetes.pods.pod` or `kubernetes.pods.pod.containers.container`, it applies the same settings to all pods. Whether is one or two. 

In the case of Spark we can be more specific by using the following paths:
  
- For the Driver pods: `kubernetes.pods.driver` and `kubernetes.pods.driver.containers.container`     
- For the Executor pods: `kubernetes.pods.executor` and `kubernetes.pods.executor.containers.container`   

Using the path to the `pod` (driver or executor) or the container it will solely depend on the parameter we are setting. 

Flink configuration works similarly to Spark's as we can set the following paths:
  
- For the JobManager pods: `kubernetes.pods.job-manager` and `kubernetes.pods.job-manager.containers.container`       
- For the TaskManager pods: `kubernetes.pods.task-manager` and `kubernetes.pods.task-manager.containers.container`  

Let's go over a per pod specific configuration of a Spark application. The following snippet adds three volumes, available to both pods, and some volume-mounts specific to each pod.

The sample below shows how to.

[source, hocon]
----
cloudflow.runtime.spark {
  kubernetes.pods {
    pod {
     volumes {
        foo {
          secret {
            name = mysecret1
          }
        }
        bar {
          secret {
            name = mysecret2
          }
        }
        baz {
          pvc {
            name = myclaim1
            read-only = false
          }
        }
      }
    }
    driver {
      containers.container {
        volume-mounts {
          foo {
            mount-path = "/mnt/folderA/mysecret1"
            read-only = true
          }
          baz {
            mount-path = "/mnt/folderB"
            read-only = false
          }
        }
      }
    } 
    executor {
      containers.container {
        volume-mounts {
          foo {
            mount-path = "/mnt/folderA/mysecret1"
            read-only = true
          }
          bar {
            mount-path = "/mnt/folderC/mysecret2"
            read-only = true
          }
        }
      }
    } 
  }
}
---- 

This configuration will mount `mysecret1` into any `driver` pod on path `/mnt/folderA/mysecret1` as read-only and into any `executor. It will mount `myclaim` into any `driver` pod on path `/mnt/folderB` as writable and `mysecret2` will be mounted into any `executor` pod on path `/mnt/folderC/mysecret2`. Inside folders `A` and `C`, you'll find as many files as values are under the https://kubernetes.io/docs/concepts/configuration/secret/#decoding-a-secret[`data`] tag in the Kubernetes Secret mounted. While the mounted `myclaim1` into the `driver` pods will allow to share the contents of folder `/mnt/folderB` among all of them. 

## Exceptions

Is important to bear in mind that flink configuration will not be able to set specific labels per type of pod (`task-manager` and `job-manager` pods). Only `cloudflow.runtimes.flink.kubernetes.pods.pod.labels` is allowed, cloudflow.runtimes.flink.kubernetes.pods.[pod type].labels is not. It has the same limitation when defining `volumes` and `volume-mounts`. Is only allowed `cloudflow.runtimes.flink.kubernetes.pods.pod.volumes` and `cloudflow.runtimes.flink.kubernetes.pods.pod.containers.container.volume-mounts`.
 
In the example below we show how a Spark driver and executor can be configured individually.

[source, hocon]
----
cloudflow.streamlets.my-streamlet {
  kubernetes.pods {
    driver {
      labels {
        key1 = value1
        key2 = value2
      }
      containers.container {
        resources {
          requests {
            cpu = "1"
            memory = "1Gi"
          }
          limits {
            memory = "2Gi"
          }
        }
      }
    }

    executor {
      labels {
        key3 = value3
      }
      containers.container {
        resources {
          requests {
            cpu = "2"
            memory = "2Gi"
          }
          limits {
            memory = "6Gi"
          }
        }
      }
    }
  }
}
----

The above example shows specific container settings for the Spark driver and executor pods. In this case, the driver pods will request `1` cpu and `1Gi` of memory, limited to `2Gi` of memory, and will be labeled with `key1 : value1` and 
`key2 : value2`. The executors will be requesting `2` cpus, `2Gi` of memory, limited to `6Gi` and will be labeled with `key3 : value3`.
