= Installing Cloudflow
:toc:
:toc-title: ON THIS PAGE
:toclevels: 2

include::ROOT:partial$include.adoc[]

This guide shows how to install Cloudflow and dependencies on Cloudflow like the Spark and Flink operator, using the `Helm` and `kubectl` command-line tools. 

== Prerequisites

=== CLI Tools

Make sure you have the following prerequisites installed before continuing:

- Helm, version 3 or later (check with `helm version`)
- Kubectl 

Before proceeding, make sure that `kubectl` is correctly installed and access the Kubernetes cluster to install Cloudflow.

=== Kafka

Kafka is used by Cloudflow to store information. Before installing Cloudflow, you need to make sure there is a Kafka cluster available and have the necessary broker bootstrap configuration.

The Kafka broker bootstrap configuration string is a comma-separated list of host/port pairs used by Cloudflow to establish the connection to the Kafka cluster. The configuration string should have the following format:

broker-1-address:broker-1-port, broker-2-address;broker-2-port

If you want to test Cloudflow and need a Kafka cluster, we recommend using Strimzi, a third-party Kafka operator that can create and manage Kafka clusters. 

The following chapter is a guide on how to configure and install a Kafka cluster using Strimzi. 

. xref:install-and-use-strimzi.adoc[How to install Strimzi and create a Kafka cluster]

=== Storage requirements

If you plan to write Cloudflow applications using Spark or Flink, the Kubernetes cluster will need to have a storage class of the `ReadWriteMany` type installed. The name of the `ReadWriteMany` storage class name is required when installing Cloudflow.

For testing purposes, we suggest using the NFS Server Provisioner.

https://github.com/helm/charts/tree/master/stable/nfs-server-provisioner[NFS Server Provisioner Helm chart]

Add the `Stable` Helm repository.

  helm repo add stable https://kubernetes-charts.storage.googleapis.com/

Update the Helm repository.

  helm repo update

Install the NFS Server Provisioner.

IMPORTANT: Depending on your Kubernetes configuration, you may want to adjust the values used during the install. 
https://github.com/helm/charts/tree/master/stable/nfs-server-provisioner#configuration[NFS Server Provisioner configuration options]

  helm upgrade nfs-server-provisioner stable/nfs-server-provisioner \
    --install \
    --set storageClass.provisionerName=cloudflow-nfs \
    --namespace cloudflow

The result of the installation, the NFS Server provisioner pod running and the new storage class.

----
$ kubectl get pods -n cloudflow
NAME                       READY   STATUS    RESTARTS   AGE
nfs-server-provisioner-0   1/1     Running   0          25s

$ kubectl get sc
NAME                 PROVISIONER            AGE
nfs                  cloudflow-nfs          29s
standard (default)   kubernetes.io/gce-pd   2m57s
----

NOTE: When installing Cloudflow, we will use the name `nfs` to indicate that Cloudflow should use the NFS storage class.

== Installing Cloudflow

In this guide, we will use Helm to install Cloudflow.

The first step is to create the namespace we want to install Cloudflow into:

  kubectl create ns cloudflow

IMPORTANT: Many subsequent commands will assume that the namespace is `cloudflow`.

First, we add the Cloudflow Helm repository:

  helm repo add cloudflow-helm-charts https://lightbend.github.io/cloudflow-helm-charts/

The `repo update` command ensures Helm has an up-to-date index of all Helm charts.

  helm repo update

Now we install Cloudflow, but before you press enter, let's go over the custom parameter we are supplying with the command:

  cloudflow_operator.persistentStorageClass=nfs

The `persistentStorageClass` parameter sets the storage class to use with Spark and Flink applications. This storage class, as previously mentioned, has to be of the type `ReadWriteMany`. In our example, we are using the `nfs` storage class, which we have installed in our cluster using.

  cloudflow_operator.kafkaBootstrapservers=cloudflow-strimzi-kafka-bootstrap.cloudflow:9092

The `kafkaBootstrapservers` parameter sets the address and port of the Kafka cluster that Cloudflow will use. In this example, we have used the address of a Strimzi created Kafka cluster located in the `cloudflow` Kubernetes namespace.

Installing Cloudflow using the Helm chart.

  helm install cloudflow cloudflow-helm-charts/cloudflow --namespace cloudflow --set \
  strimzi.enabled=true --set cloudflow_operator.persistentStorageClass=nfs --set cloudflow_operator.kafkaBootstrapservers=cloudflow-strimzi-kafka-bootstrap.cloudflow:9092

Check the status of the install process using `kubectl`. When the Cloudflow operator pod is in `Running` status, the installation is complete.

----
$ kubectl get pods -n cloudflow
NAME                                                READY   STATUS    RESTARTS   AGE
cloudflow-operator-6b7d7cbdfc-xb6w5                 1/1     Running   0          10s
----

You can now deploy an Akka-based Cloudflow application into the cluster as it only requires Kafka to be set up. More on this in the development section of the documentation.

== Installing the Spark operator

If you plan to write applications that utilize Spark, you will need to install the Spark operator before deploying your Cloudflow application.

The Spark operator used is currently maintained by Lightbend and is presently the only Cloudflow compatible version.

Add the Spark Helm chart repository.

  helm repo add incubator http://storage.googleapis.com/kubernetes-charts-incubator

As we have seen before, we need to update the Helm repo before installing Spark.
  
  helm repo update

Before installing the Helm chart, we will need to prepare a `value.yaml` file, it overrides the default values in the Spark Helm chart.

----
cat > spark-values.yaml << EOF
rbac:
  create: true
serviceAccounts:
  sparkoperator:
    create: true
    name: cloudflow-spark-operator
  spark:
    create: true
    name: cloudflow-spark

enableWebhook: true
enableMetrics: true

controllerThreads: 10
installCrds: true
metricsPort: 10254
metricsEndpoint: "/metrics"
metricsPrefix: ""
resyncInterval: 30
webhookPort: 8080
sparkJobNamespace: ""
operatorImageName: "lightbend/sparkoperator"
operatorVersion: "2.0.7-cloudflow-spark-2.4.5-1.1.2-scala-2.12"
---
kind: Service
apiVersion: v1
metadata:
  name: cloudflow-webhook
  labels:
    app.kubernetes.io/name: sparkoperator
spec:
  selector:
    app.kubernetes.io/name: sparkoperator
    app.kubernetes.io/version: 2.0.7-cloudflow-spark-2.4.5-1.1.2-scala-2.12
EOF
----

Now we can install the Spark operator using Helm. Note that we use a specific version of the Spark operator Helm chart.

  helm install spark-operator incubator/sparkoperator --namespace cloudflow --values="spark-values.yaml"  --version "0.6.7"

IMPORTANT: If you are installing the Spark operator on *OpenShift*, you need to apply the following `rolebinding` to the cluster.

----
cat > spark-rolebinding.yaml << EOF
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: system:openshift:scc:anyuid
  namespace: cloudflow
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: system:openshift:scc:anyuid
subjects:
- kind: ServiceAccount
  name: cloudflow-spark
  namespace: cloudflow
EOF
----

To apply the `spark-rolebinding.yaml` file execute the following command. Note that this has *only* to be performed if you are installing Cloudflow on Openshift.

  oc apply -f spark-rolebinding.yaml

After the Spark operator installation completes, we need to adjust its webhook configuration.

----
$ kubectl get pods -n cloudflow
NAME                                                READY   STATUS    RESTARTS   AGE
cloudflow-operator-6b7d7cbdfc-xb6w5                 1/1     Running   0          109s
spark-operator-sparkoperator-56d6ffc8cd-cln67       1/1     Running   0          109s
----

For this, we will create yet another YAML file that we will apply to the cluster with `kubectl`.
----
cat > spark-mutating-webhook.yaml << 'EOF2'
apiVersion: batch/v1
kind: Job
metadata:
  name: cloudflow-patch-spark-mutatingwebhookconfig
spec:
  template:
    spec:
      serviceAccountName: cloudflow-operator
      restartPolicy: OnFailure
      containers:
        - name: main
          image: alpine:3.12
          command:
            - /bin/ash
            - "-c"
            - |
              apk update && apk add wget
              wget -q -O /bin/kubectl https://storage.googleapis.com/kubernetes-release/release/v1.16.12/bin/linux/amd64/kubectl && chmod 755 /bin/kubectl
              NAME="spark-operator-sparkoperator"
              API_VERSION=$(kubectl get deployment -n cloudflow $NAME -o jsonpath='{.apiVersion}')
              UUID=$(kubectl get deployment -n cloudflow $NAME -o jsonpath='{.metadata.uid}')
              KIND=$(kubectl get deployment -n cloudflow $NAME -o jsonpath='{.kind}')
              HOOK_NAME="spark-operator-sparkoperator-webhook-config"
              JSON=$(cat <<EOF
              {
                "metadata": {
                  "ownerReferences": [
                    {
                      "apiVersion": "$API_VERSION",
                      "blockOwnerDeletion": true,
                      "controller": true,
                      "kind": "$KIND",
                      "name": "$NAME",
                      "uid": "$UUID"
                    }
                  ]
                }
              }
              EOF
              )
              echo $JSON
              kubectl patch MutatingWebhookConfiguration $HOOK_NAME -n cloudflow -p "$JSON"
EOF2
----

Now we can apply the changes to the webhook.

  kubectl apply -f spark-mutating-webhook.yaml --namespace cloudflow

That completes the installation of the Spark operator. 

----
$ kubectl get pods -n cloudflow
NAME                                                READY   STATUS      RESTARTS   AGE
cloudflow-operator-6b7d7cbdfc-xb6w5                 1/1     Running     0          3m29s
cloudflow-patch-spark-mutatingwebhookconfig-66xxb   0/1     Completed   0          21s
spark-operator-sparkoperator-56d6ffc8cd-cln67       1/1     Running     0          3m29s
----

== Installing the Flink operator

If you plan to write applications that utilize Flink you will need to install the Flink operator before deploying your Cloudflow application. As we can see below, the CLI will not allow you to deploy an application that does not have all dependencies installed.

  $ kubectl cloudflow deploy cloudflow/examples/taxi-ride/target/taxi-ride-fare.json
  [Error] cannot detect that Flink is installed, please install Flink before continuing (exit status 1)

The Flink operator used is a version currently maintained by Lightbend and is the only Cloudflow compatible version.

Install the Flink operator using the following Helm command:

----
helm install flink-operator \
https://github.com/lightbend/flink-operator/releases/download/v0.8.2/flink-operator-0.8.2.tgz \
--namespace cloudflow --set operatorImageName="lightbend/flinkk8soperator" --set \
operatorVersion="v0.5.0"
----

This completes the installation of the Flink operator. 

----
$ kubectl get pods -n cloudflow
NAME                                                READY   STATUS      RESTARTS   AGE
cloudflow-operator-6b7d7cbdfc-xb6w5                 1/1     Running     0          3m29s
cloudflow-patch-spark-mutatingwebhookconfig-66xxb   0/1     Completed   0          21s
spark-operator-sparkoperator-56d6ffc8cd-cln67       1/1     Running     0          2m29s
flink-operator-7999fdd879-phqlg                     1/1     Running     0          1m29s
----

== Installing Enterprise components
If you have a commercial agreement with Lightbend, you are eligible to install the Cloudflow Enterprise components. 

Before installing, you need to make sure you have the credentials required to download the Helm chart from the Lightbend commercial repository.

Add the Lightbend Helm repository.

  helm repo add lightbend https://repo.lightbend.com/helm-charts/

Update Helm to make sure all charts are up-to-date

  helm repo update

Install the components, note that you set the `$USERNAME` and `$PASSWORD` environment variables before executing this command. 

We recommend using the following command to create an environment variable for username and password. 
*This is to avoid storing this information in the shell's history file.*

  read USERNAME
  read -s PASSWORD

TIP: If you want to see the password typed in, remove the `-s` (for silent) flag.

Once configured, we can execute the Helm command to install the Cloudflow enterprise components. Note how we use the `$USERNAME` and `$PASSWORD` in the Helm command.
 
----
helm upgrade cloudflow-enterprise-components lightbend/cloudflow-enterprise-components \
  --install \
  --namespace cloudflow \
  --set enterpriseOperatorVersion=2.0.8 \
  --set enterprise-suite.imageCredentials.username="$USERNAME" \
  --set enterprise-suite.imageCredentials.password="$PASSWORD"
----

After we have used the username and password environment variables, we can clear them by closing the shell or executing the following commands:

  unset USERNAME
  unset PASSWORD

To quickly verify that the installation worked, you can open a proxy to the Lightbend console service and confirm that you can access the Lightbend console UI.

First, create the port-forward.

  kubectl port-forward -n cloudflow svc/console-server 5000:80

Then open the following URL in your browser:

  https://localhost:5000

You should now see the Lightbend console in your browser.

== Upgrading Cloudflow

If you need to upgrade Cloudflow to a newer version, the following chapter in the administration section will show you how.

. xref::administration:upgrading-cloudflow.adoc[upgrading Cloudflow].

== What's next

Now, we are ready to xref:deploy-to-k8s-cluster.adoc[deploy an example application to the cluster].
